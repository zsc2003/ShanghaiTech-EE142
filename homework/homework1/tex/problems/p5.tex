\textcolor{blue}{Problem 5}

2.14 Entropy of a sum. Let $X$ and $Y$ be random variables that take on values $x_1, x_2, \ldots, x_r$ and $y_1, y_2, \ldots, y_s$, respectively. Let $Z=$ $X+Y$.

(a) Show that $H(Z \mid X)=H(Y \mid X)$. Argue that if $X, Y$ are independent, then $H(Y) \leq H(Z)$ and $H(X) \leq H(Z)$. Thus, the addition of independent random variables adds uncertainty.

(b) Give an example of (necessarily dependent) random variables in which $H(X)>H(Z)$ and $H(Y)>H(Z)$.

(c) Under what conditions does $H(Z)=H(X)+H(Y)$?

\textcolor{blue}{Solution}

(a)



(b)



(c)



